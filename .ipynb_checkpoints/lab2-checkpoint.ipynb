{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO411 Lab 2 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our last lab we had our first encounter with Numpy, which is a handy tool for us to manipulate vectors and matrices. In this lab, we continue with the exploration of Numpy, and Pyplot (for visualization), but the main objectives are:\n",
    "- Gain more understanding of k-means, EM and DBSCAN by working on some simple data sets\n",
    "- Get started with Sklearn, a machine learning package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with the simple k-means demo written in NumPy. As usual we import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we generate two 1-D random data blobs using normal distributions, each with 100 points (what are the centre values?). Note the 'spread' for both Gaussians is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.random.randn(100)+2\n",
    "d2 = np.random.randn(100)+8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show them up on the screen. Note that for better visibility the array index is used for the x-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10954ba10>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHQpJREFUeJztnW2sZVV5x/+PjCiDBcSZGAqOgwmxoSZV5o7V1pS5nbaC\nkmKalNCEW9vYTEL6Qk2TCcTA3IEPlmmv0Q+VhKBCLEEnSJTwoS8yd/CbnTuVGt5UfEGwINeIffFD\nwfj0wz7H2ffM2fusvfd6edba/19yMvec2efs9fpfz3rWs9YWVQUhhJD8eVXqBBBCCPEDBZ0QQgqB\ngk4IIYVAQSeEkEKgoBNCSCFQ0AkhpBAo6IQQUggUdEIIKQQKOiGEFMK2mDfbsWOH7t69O+YtCSEk\ne06ePPkjVd256Lqogr57925sbGzEvCUhhGSPiDzjch1dLoQQUggUdEIIKQQKOiGEFAIFnRBCCoGC\nTgghhUBBHzlHjgDr61s/W1+vPieE5AUFfeTs3Qtcc80pUV9fr97v3Zs2XYSQ7kSNQyf2WF4Gjh6t\nRPz664E77qjeLy+nThkhpCu00B0o3S2xvFyJ+W23Vf9SzAnJEwq6A6W7JdbXK8v85purf2cHL0JI\nHlDQHai7JW65pfq3FLfEdHA6ehS49dZT+aSoE5IfFHRHSnVLnDixdXCaDl4nTqRNFyGkO6Kq7ReI\nfBrAVQBeVNW3TT47H8DnAewG8D0A16jqS4tutrS0pLkezjW1ZLlwSAiJjYicVNWlRde5WOh3A7hi\n5rMbATysqpcAeHjyvljolhgPpS+Ak7JZKOiq+hUAP575+GoA90z+vgfABzynyxR0S4yH0hfASdks\ndLkAgIjsBvBQzeXyE1U9b/K3AHhp+n7Odw8AOAAAu3bt2vPMM07H+hLDHDlSCVzd5bS+Xg1wBw+m\nS5cv6F4j1vDpcmlFqxGhcVRQ1TtVdUlVl3buXPjADZIBXa3Y3NwYpS6Ak/LpK+g/FJELAGDy74v+\nkkSs0zWMMzc3Rt+4/NgDV24DJYmAqi58oYpmeaz2/u8A3Dj5+0YAR1x+Z8+ePUrK4eabVYHq30Uc\nO6a6Y0d17Y4d1XuLTNM5Td/s+1DfjZ1Wn9x+++n3PHas+pz4AcCGumj1wguA+wA8D+AVAM8B+BCA\nN6CKbvkWgC8DON/lZiEEnY0pDX0EussAkIqh7Sn2wGVhoLQysJSMN0H3+Qoh6GxM8Qe1PmVuQXhi\nEXvgsjBQjql+UzAaQVdlY4o9qHUdQMY06IZui7Nlf+yY6rnnqu7fn75MLQwspTIqQVdlY7I8qI3F\nLRZj4Kr/5lTMzznn1PvUbheL7a8ERiXobEwVYx/UUhNr4Jq29/37T4l5yPu5pmcMM7BUjEbQ2Zgq\nOKiNiz6Dd6gBZywzsJSMRtDH1Jia8nrgQLdBrel3rryy7LIspa30Hbzr7eL221XX1k5vN7mVxVgY\njaCPiabZyIEDfhYp53Xwkqx9X7O5lAPD0DxMr19ZURWp6rzP75C4UNALxZdrpel3Snfd+MhfSjef\nj8Fk6q5ZWSm7rkuCgl4wvhY/m36n9MVVH/nLdeCbTffKStl1HYMYMzYKeqHQQh+Gz/zlNvDNziTW\n1iq3y9RSL62u5xFCfGPM2CjoBeKr4dCHPv99n9/KaeCri1m9zqef+86HxUXoUOIbuj1Q0AvEVwdh\nlMsp+uSvhFDZGGJrtZy6iG+Xcgo5Y6Ogk+KwYvFZSUcOWJ3JuIqv66BEC32EUAiGYdXiKxmfUTVW\n1hq6iu+i6+vtMFR8PwW9B6EFl4LUHcuHUY2BoW02lYXuaxPelLZBKcbaBAVdbZ4KaHUKapV5dXLW\nWbYsvq7kNlPr22Zd+lO9LKZ/18uib7k03bvrJrz6d31Z9H2goGs/gY4huNamoNap18k551QWupUB\nsY84x5yp+Ro8Qp0dU8/7dPbl6/RIH325b1357uMU9Al9KjWk4NJC78e0TrZvt+Wy6tvhY7UDH4NH\n6LSGHLCH9uUhAzYt9ED0efZliKNJx+RD9+lWCFknPpjXgV3yH2umNkRgYrXZeln4KpcUxlOo8ipO\n0PsKRJdKDTn9G5KHHPHVsHMZBGdFaFG6Y4tNX5EM0WbbFrp9Weip2k2oPl6coA/xh7t+J0RExZhE\nfBYfopVD+TXlc9HnscTGmpuvyXBaW/NnROXQbrpQnKCrdm+YFmJo2zpvaY1uHqUvAC8S53n5j1nv\nVmc489xoPqNcSqNIQVeNKxC+LBsrllps+vqWc6ItPxYsY8vlXfpg75MiBT1mB2kS2z5xrKrNjddC\npw9BU/mVfgDYlNIH66EsaveWB6IUFCfos66K0I/P8rnTbFHjLdFSsW65hoaC1IzLYMcBcSvFCXrs\noz/b6CJIixpmX3FzEQzLolLiIEbccG2XKdbMrFKcoM+S2spzFSQXS7WPFZKzlZO67kg+9NlDYq29\n+yCKoAP4MIDHATwG4D4Ar2273vfGolRWni9BGmpRuKTDmniW3OmIX/q0XWvt3RfBBR3AhQC+C+Cs\nyfujAP6k7TslWOixBWmR6LsMapbcG1amxaEOhSJ+GNLPLLV3X8QS9GcBnA9gG4CHAPxe23d8CXpK\nKy+UIPVZhM3RQrfCbDn63hXsipUBro6FJ1rF2BkeK00+iOVyuQHA/wLYBHDvout9CXqfgo2xhXnI\nb7YNUvMaaWgfukWh8U29XFOd4mjRBdWUJushp6HLMmVdxbDQXw/gGICdAF4N4IsArptz3QEAGwA2\ndu3aFT7nDYSoDN+/2WZdzE4jQ0e5WBSaEIQ4FGqWRfVgcRbVlCaLaZ0SwwiZ5j/2QXExBP0PAXyq\n9v6PAXyy7Tupn1gUojH6ruB5opKqE1nuvD6IZaG7DI4pjnldRFOaSvRRdyHFUc4xBP3XJxEu2wEI\ngHsA/GXbd1ILumqYxuirgvu6VkJSaueN7UNvGxx9DJyxZoulD/KLSOWmi+VDPwzgqUnY4mcBvKbt\n+tSCHtJCH1rBTR2y61EDIfz6JXZelygX34uAbbOvNiEOtRGniVx96E346hPzymXR4xB93bv4jUVd\nieVD7/u8y5CNrk8+Y88MLC7C+iyDJrHt+pi2RenwMaNyiXLJKdQzlLE0ndm1Ha/tqw1R0GeIfVB/\nSsvFh6UWW2BTu5YWpSu1O8QlHTFnVFbrq4l5ZTMkD12+66NeKOiRsdbAc/R9W3XxWFmwbEtHivbX\npb4szMB8Bhx0zc/QNkRBj4yFBlu/72wjjZG+rveYd/3Kiq2ByMogsygdqdqfq1ClNnjayi+08UML\nnfSmqePEWNDq2mln/39tTVVE9bLLbDwMOrUIWUtHU7pchSrV4NhWfqHTRB86GUTqc8j7dvKVlUrM\n19ZOrUWk2IpfJ+Wsy/pZM32FKoUr0OezDXzdm1EuIyKkkMToUF3vMb1+ZeXUZ1NRT73AnAqrVvmU\nPm3UivtqiiU36SIo6BkTqjNbttBT+DatY00Ah2B9gLIOBb2FHEZm3505Roca6kP35du0fhBbF0oZ\n1HLoc5ahoLeQi7XgszPnEuXiw7cZon5TtJmSLHQyDAr6AkJ2Fh/imUtntmoNT8vP56l4MeskF6OD\nxIGC7kCo6ezQzphTZ7ac1hCn4sVygcR0UdAdYh8K+gJCWHDzft+KDzgkFmcT9TT5OhXPYj59YHlQ\nToHF/kdBb2F28S1UzHMpC1oupM5rvRNO63Bt7dTnfQ9Nm1K66JU6WPXBYl1T0FuIcajWmDqIhbzW\nO93tt2/dGeujfi1abb5JPShbwkKbrkNB74jPxmxxhB9Kyt12rszrhCXWRQisCZgFLA1wFPQO+G7M\nJVpzTcLY9Uzp0Mx2whLrwjcc9E7H2gBHQXeEjdkda418Fuvps4rPQa+EAdSiJlDQHSmhAcbE0jS0\njsVOOEZC14PFDXIxoKAT71iygGc73XQhdPbRbRyY4xOynYx14KagE69Y60jW0kO2EnImZ8mwiIWr\noL8KhDhw4gRw9CiwvFy9X16u3p84kSY90/tfcw1wyy3Vv/X0jZkjR4D19a2fra9Xn8dgfR244w7g\n5purf2fTMpTlZeD664Hbbqv+9VHnqcvMGy6q7+tFC534xqpPPyUpZy8h7t22b2T79srVNpuGrq42\n6zM+lOBysbg4Qewwxqm3K6nKJkSfrYvrVMynO7unjy2civoQIbbcnooQdOujJkkH28ZiSpq9TOt3\n3tlLa2uqZ5/tR4itllkRgq5qe9Qk6eDsrZ0S+02b2PoQYstlVoygq9odNQmxSImzlzax9SHE1sss\niqADOA/A/QCeAvAkgHe3XR/aQqfVRkh5/aBNbH0JsfUyiyXo9wD4s8nfZwI4r+360D5066MsIaQ7\nbWJrXYh94SroUl3bHRE5F8CjAN6ijj+ytLSkGxsbzvc4cgTYu3drnOn6ehX7fPDg/O+sr1cxyddf\nX8XAMjaZEJI7InJSVZcWXTdkY9HFADYBfEZEviYid4nI2QN+7zQOHjxdjJeXm8V8+v++Nx0QEoNi\nNreQZAwR9G0ALgNwh6q+A8BPAdw4e5GIHBCRDRHZ2NzcHHA7N0LvUiMkFHv3VrPLaZudzjb37k2b\nLpIPQwT9OQDPqepXJ+/vRyXwW1DVO1V1SVWXdu7cOeB2i5l2gKNHgVtvPbU1nKJOcoDHGZCh9BZ0\nVX0BwLMi8tbJR/sBPOElVT2xdt4IIV2hy5AMofeiKACIyNsB3IUqwuU7AP5UVV9qur7roighY4OL\n+mQeroui24bcRFUfBbDwJoSQxdRdhsvL1YtuF9IFHp9LiBHoMiRDGeRy6QpdLoQQ0p0YceiEEEIM\nQUEnhJBCoKATQkghUNAJIaQQKOiEEFIIFHRCCCkECjohJBtWj6+mToJpKOiEkGw4/Mjh1EkwDQWd\nEGIOWuL9oKATQsxRt8RXj69CDgvksADAL/6m6J/OoMO5CCEkNKv7VrG6bxVAJeZ6KN5xJblBC50Q\nYgJa4sOhhU4IMYGLJX7o8kORU5UXtNAJIdkwFXwyHwo6yQZOvccDLfF+UNBJNjAGeTzQEu8HBZ0Q\nQgqBgk5Mw8gHQtzhI+hINjAGmYwVPoKOEEJGBgWdZAMjHwhph4JOsoGRD4S0Q0EnhJBCoKATQkgh\nDBZ0ETlDRL4mIg/5SBAhhJB++LDQbwDwpIffIRMYY00I6cMgQReRiwC8H8BdfpJDAG5xJ4T0Y6iF\n/nEABwH83ENaCCGEDKC3oIvIVQBeVNWTC647ICIbIrKxubnZ93bFwy3uhJCh9N76LyIfBbAC4GcA\nXgvgHAAPqOp1Td/h1n83uMWdEFIn+NZ/Vb1JVS9S1d0ArgVwrE3MCSGEhIVx6AbhFndCSB+8CLqq\nHlfVq3z8FuEW99hYWaewkg6SL7TQyeixEiZqJR0kXyjohBBSCBR00pkSXANDwkR95p/hqsQnfGJR\nA6vHV+nLbqC0sMqu+QmV/9LKlfiDTywaiBV/Ji01QogrFHTjWBpYSnUNuISJxsg/w1XJUIpyuQx1\nk6weX50roIcuP5TM/WJxGm4xTTEZe/4BuiRjMxqXS91CGmrNru5bhR7SX3TW6d+xG27J1nDJjKl+\nrMwcyVayF/QSG5aVgaWJsbsGmvJfYlsk3Ug9qGcv6ACCWLPWRSt0w2n7fSsDSyrGmv+cZo6p0pR8\nUFfVaK89e/aoDw6tH1KsYu6rNA6tH5r7eVNem67vSollGYKmtuirHqxivX3U0xezLkKVC4ANddDY\nLAV9S0ZrBTi0MHPqhE159dWgrHfYPoSu3xLLrAnrefWpC4uIMai7CnoRLpcpQ90kyadLCwg95c1p\nSt0H6/WbExZdkk3tN/h9Da15ZR+26DN8KqdwtHpaQ4Rb5lQWroTOE0P57NAk5KFDkIPtInYMW8ze\n5TKUXH2gvlwuXX30uZFr/ZJhxHS51AnVrlCaDz1GB8xJxHwJcejFVUvkVL9kGPX267JAar29uwp6\nNj50+j+3hmI1TRt9+TbpOiA5U2+/9T7RpCOl6Es2gh4Diws9dVwanYsQl7742YT1+iVhGJNxYnpR\n1OLZKnViL4KFWHAZ+ptcCCTWadKRy998OR555pHTPreiL3VcF0VNC3odi1EXTWnyKXKhB7Wh5Wqx\nXghpoqm9Wm/HozmcKwZdXRE+/XGhY1zphnCjdHcUKYNsBD2l8NQFusn/vO/ufYlSN4w+A0NpZeBC\nKYtmlokxaDbpSDGGjUsojK+Xz7NcYuIS8910tozPtFoMrUoV7xubIXmzWG8Wyan9RNeg0sIW68Sw\nlvpEgoTe/mttoaZ0fEUD5Wzdd83rWFxTVus0m0XROrEjM5rut+/ufXNXyQFs2ZZfshA3lYHFSIEh\nDGlz1hfc2gj9AG3rkWxNxK7T4rb+d93C3TYlGrKb0mWHZtMutdIpOa99jlQowQXna+dx6O/GIOUx\nEgi99R/AmwCsA3gCwOMAblj0HV8+dJeKn71miMi6fNfX2So5U8KZGSHuF6pcQv1uH+PJh9Dl1Fdi\npzWGoF8A4LLJ378E4JsALm37TkpB97Vo6XL2yVgPhCrhQQIhyE3Qh9xjLIvHxQn6aT8EfAnA77Zd\nEzrKpU1Ih0RjDBHonIQnJSVbc77dLDGNhZiCnhNWo1x8ifluAN8HcE7bdTGPz60L+bzXkN8NeX1K\nUroxXMpprDOfJoa4DkN9Z6x1MY8UTyzyIeavA3ASwB80/P8BABsANnbt2uUtg4uY53KZEtMfmlMD\njzH4NIl4yQNlKHyVmWsbtd6WraXPZxt1FfRBcegi8moAXwBwr6o+0BBFc6eqLqnq0s6dO4fcrhNt\nO7+GhEN13VFmOfQqBbMhamM89dEXvnY3usZU+4q9DlW/VmPDY9Jb0EVEAHwKwJOq+jF/SfLDrJDy\nnPBTbDlX/Xj8o3SbnvXYZTNWMVu1HZitr1/87VBOFo9Knj1KIxUh7p28vF3M+HkvAO8BoAC+DuDR\nyet9bd+x+Ai6MRI7xNJlLSPkvXPHVznNuh1d1iNCrFv4rHcLAQsxHuOI0h5BR/wRW9Cb7uFrXcP1\nfiGIvbknxIK+628ODUn0HaAwNH2+7h2jP7kKepZnuZDuuEwFfboxXKaY9fvl6soK5bdtqq/6312n\n8SndVLPHQNeJ6ZaI6RJJUt4uqu/rNXYL3cr0P7YlXidGGcQMb4yRz9CuqdhRLqHyE3MvQ/T9AHS5\n2MNKqF1KQY9NCMF16cyhXAlWynUIVs46Cu1y8YmroNPlMkJCTQWTr/DX0rGIIa6S0E+RmqVeXxaj\nezofsVsrp5T5abp31mGzLqrv6zVGC32suxutWF6hIxD6RI6URgmzhjpd81PEaYt9XmMU9DqlNfw2\nrAh6nRCCGyNkzTolRBLVSbn+04SroNPlUjApp46xp9Iu7p4QrhIr0Tkp3Fqx3GtWnlCWxU5UF9X3\n9Rq7hW7F0igdl3yPxaos4d6x89bksktaxrTQ7VG35rJeeIlIqHIKPYNIabmX0LasLLAffuSwiXQ4\n46L6vl5jt9DrhIq/LW1hrk85+cqr9TKLsfvSNR0hSZkfKyGjcLTQs3xIdAn4fMhs02/l/HDiKSnz\nkFP51dOaU7pdiJ2fpgdXA0jXFh0fEk2XS0SsTCOtM6Zy8pmnUsss+gJ7w+K5xT0Ap+Fixvt60eVy\niqHTNxfXinWXgQsppttRt3R7yp+vxbsS2oxPrAQWgHHotgm1Nbw0So7eCHWPIb9Zclvqg5UBzlXQ\n6XJJRBbTNwOUWE5OMfMDXCUWyyxX14+VfQbOuKi+rxct9DBYsSJKI/ZZ5y6fd8UlDzHcTLT8hwFG\nuRBin9ARSl1/J1RESWmRN7FhlAshGbDlIR+FRfeUlp8coIVOSI3V46sm/KZDLNqmOOpDlx9amLdQ\n+aeFPgxa6IT0IIsDmBbgcghZk5VsYTArlRgzEwo6IQYJHakSe+CyGHkTmxhlTkEno8eir9eXpWxF\nSGn5x4E+dCNY8d2OnZJ9vUN866Qfvsrc1Yc+ekG3IqQlC0lXUtbJWOphLPm0xJAy56KoIyUsgpVG\nyjqx4qIgpA+jF/SUWPTdjh0Ls7UYcOCKT4wyH+RyEZErAHwCwBkA7lLVv2273orLxaIvMfQU2Ipr\nqQmLdUKIFVxdLr3PZUEl4t8G8BYAZwL4DwCXtn3H4lkuVs6YsPxcRuvPx+RZNqR0EOG0xXcCeFpV\nv6OqLwP4HICrB/zeqLE8Bba+zmA9fWOFrsP4DBH0CwE8W3v/3OSzrLAipCHcCrn66K3UCRlG6IHW\nejtOQfBFURE5ICIbIrKxubkZ+nadKdk/67IFvPG7CQcD6+kbgvX05QRnZqfTe1FURN4NYFVV3zt5\nfxMAqOpHm75jZVF0jAyKgTUes2w9fXVySmsfYi5ul16WdWLEoZ8AcImIXCwiZwK4FsCDA36PBIRu\nDBKDIbNCp9/PdGYWi219v6iqPxORvwDwz6giXj6tqo97SxnxypAOZX0wsJ6+Wat1KkYMyezO6r5T\n4bdjstBdGf3Wf0JiMiYRCr33YUxlya3/hJCkhJ59WJ+ZpYCCTkhEKEL+oLvqdCjohESEIkRCQkEn\nhJBCoKATQkghUNAJIaQQKOiEEFIIFHQSHO7iIyQOFHQSHB6iREgcKOiEEFIIFHQSBB6iREh8eJYL\nCc6YztwgJAQ8y4UQQkYGBZ0Eh+eXEBIHCjoJDs8vISQOFHRCCCkECjohhBQCBZ0QQgqBgk4IIYVA\nQSeEkEKIurFIRDYBPNPz6zsA/MhjcnJhjPkeY56BceZ7jHkGuuf7zaq6c9FFUQV9CCKy4bJTqjTG\nmO8x5hkYZ77HmGcgXL7pciGEkEKgoBNCSCHkJOh3pk5AIsaY7zHmGRhnvseYZyBQvrPxoRNCCGkn\nJwudEEJIC1kIuohcISLfEJGnReTG1OkJgYi8SUTWReQJEXlcRG6YfH6+iPyriHxr8u/rU6fVNyJy\nhoh8TUQemrwfQ57PE5H7ReQpEXlSRN5der5F5MOTtv2YiNwnIq8tMc8i8mkReVFEHqt91phPEblp\nom3fEJH3Drm3eUEXkTMA/AOAKwFcCuCPROTStKkKws8A/I2qXgrgXQD+fJLPGwE8rKqXAHh48r40\nbgDwZO39GPL8CQD/pKq/AuDXUOW/2HyLyIUA/grAkqq+DcAZAK5FmXm+G8AVM5/Nzeekj18L4Fcn\n3/nkRPN6YV7QAbwTwNOq+h1VfRnA5wBcnThN3lHV51X13yd//w+qDn4hqrzeM7nsHgAfSJPCMIjI\nRQDeD+Cu2sel5/lcAL8F4FMAoKovq+pPUHi+AWwDcJaIbAOwHcB/osA8q+pXAPx45uOmfF4N4HOq\n+n+q+l0AT6PSvF7kIOgXAni29v65yWfFIiK7AbwDwFcBvFFVn5/81wsA3pgoWaH4OICDAH5e+6z0\nPF8MYBPAZyauprtE5GwUnG9V/QGAvwfwfQDPA/gvVf0XFJznGZry6VXfchD0USEirwPwBQB/rar/\nXf8/rUKSiglLEpGrALyoqiebriktzxO2AbgMwB2q+g4AP8WMq6G0fE98xlejGsx+GcDZInJd/ZrS\n8txEyHzmIOg/APCm2vuLJp8Vh4i8GpWY36uqD0w+/qGIXDD5/wsAvJgqfQH4TQC/LyLfQ+VK+20R\n+UeUnWegssKeU9WvTt7fj0rgS8737wD4rqpuquorAB4A8BsoO891mvLpVd9yEPQTAC4RkYtF5ExU\nCwgPJk6Td0REUPlUn1TVj9X+60EAH5z8/UEAX4qdtlCo6k2qepGq7kZVr8dU9ToUnGcAUNUXADwr\nIm+dfLQfwBMoO9/fB/AuEdk+aev7Ua0TlZznOk35fBDAtSLyGhG5GMAlAP6t911U1fwLwPsAfBPA\ntwF8JHV6AuXxPaimYV8H8Ojk9T4Ab0C1Kv4tAF8GcH7qtAbK/z4AD03+Lj7PAN4OYGNS318E8PrS\n8w3gMICnADwG4LMAXlNingHch2qd4BVUs7EPteUTwEcm2vYNAFcOuTd3ihJCSCHk4HIhhBDiAAWd\nEEIKgYJOCCGFQEEnhJBCoKATQkghUNAJIaQQKOiEEFIIFHRCCCmE/wfh9ql3S6aujQAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108a3ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import the plotting package; use inline display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "## plot two subsets using different markers\n",
    "plt.plot(d1,'g+')\n",
    "plt.plot(d2,'bx')\n",
    "\n",
    "# the axis 0 - 100 is the array index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for better visualization we \"expand\" the 1-D data for 2-D display using the array index for the x-axis.\n",
    "\n",
    "We then concatenate the two data clouds into one bigger array (with 200 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.concatenate((d1,d2),axis=0)\n",
    "nrow=len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and we shuffle the rows to get the data mixed up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.random.permutation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do k-means clustering, now we randomly initialise the membership for Cluster 1 (and therefore for Cluster 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memb1=np.random.randint(0,2,nrow)\n",
    "memb2=1-memb1    # membership to Cluster 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the iterations begin: update centres; update membership; ... we run 20 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate for a number of times and see if convergence is reached. \n",
    "## c1 and c2 are the two cluster centres. \n",
    "## This updates the centres, then membership, and loops around\n",
    "for it in range(20):\n",
    "   c1=sum(data*memb1)/sum(memb1)\n",
    "   c2=sum(data*memb2)/sum(memb2)\n",
    "   # if distance to c1 is smaller it belongs to cluster 1, memb1=1; otherwise memb1=0\n",
    "   memb1=np.less(np.abs(data-c1), np.abs(data-c2)).astype(int)\n",
    "   memb2=1-memb1\n",
    "   print c1,c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now display the cluster centres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the cluster centers\n",
    "plt.plot(d1,'g+')\n",
    "plt.plot(d2,'bx')\n",
    "plt.plot(nrow/4,c1,'r^')\n",
    "plt.plot(nrow/4,c2,'r^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the algorithm seem to work? Why?\n",
    "\n",
    "Your Answer: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task A**. Suppose there is an outlier data point, data[80]=200. Insert it, repeat the experiement above and comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code for Task A ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your comments: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task A***. Use the fuzzy c-means scheme with r=2 to decide membership and repeat the experiment. Does it work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code for Task A* here... Run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on the outcome:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the code and do the clustering using EM instead. Let's cleanse the outlier out first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[80]=np.random.randn()+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try EM (simplified)\n",
    "## Random initialization again. Alternatively, k-means can be used.\n",
    "memb1=np.random.randint(0,2,nrow)\n",
    "memb2=1-memb1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following gives the iterations of a simplified EM process. First the two centres are updated using weighted average of members, then the variations. The memberships are then tuned as $e^-\\frac{(x-c)^2}{2s}$ and then normalized. This continues and after a number of iterations the outcome stablizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now the iterations\n",
    "for it in range(50):\n",
    "    # update centres\n",
    "    c1=sum(memb1*data)/sum(memb1)\n",
    "    c2=sum(memb2*data)/sum(memb2)\n",
    "    # update 'spread' - the variations\n",
    "    s1=sum(memb1*(data-c1)**2)/sum(memb1)\n",
    "    s2=sum(memb2*(data-c2)**2)/sum(memb2)\n",
    "    # print the center and std\n",
    "    print 'it=',it,':', c1,'/',np.sqrt(s1),'||',c2,'/',np.sqrt(s2)\n",
    "    # re-calculate memberships using the center and std values\n",
    "    memb1=np.exp(-(data-c1)**2/s1/2)\n",
    "    memb2=np.exp(-(data-c2)**2/s2/2)\n",
    "    # normalise\n",
    "    memb1/=(memb1+memb2)\n",
    "    memb2/=(memb1+memb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code above a couple of times, and see whether it manages to calculate the centres and the spreads of the two Gaussians. Are the clusters correctly located?\n",
    "\n",
    "\n",
    "** Task B. **\n",
    "Now, let us take a look whether EM can model data \"clouds\" of different sizes. For this, comment off the random initialization again. Find the line with 'd2' assignment, and modify it into \"d2 = np.random.randn(100)*1.5+8\". This means the second cloud has now a bigger spread (stdev=1.5). Run the code to this line, and note what the result tells you about the Gaussian centres and their spreads. If the result is not quite right, try a few more runs.\n",
    "\n",
    "Then, reuse the code in Part A and conduct k-means clustering to *initialize* the cluster centers and then carry on with EM. Does this work better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## your code for Task B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your comments: ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been working on 1-D data points. Let's add another dimension so that they can be properly displayed on the screen. The following k-means code, is good for general-purpose clustering - note there are quite a few changes made to the previous code, mainly to deal with arrays of higher dimensionality. The algorithm is simplified, without looking at stdev of the clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate two random data 'clouds' around [2,2] and [8,8], each with 100 points\n",
    "d1 = np.random.randn(100,2)+2\n",
    "d2 = np.random.randn(100,2)+5\n",
    "## show them up on the screen. \n",
    "plt.plot(d1[:,0],d1[:,1],'g+')\n",
    "plt.plot(d2[:,0],d2[:,1],'bx')\n",
    "plt.grid(b=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, stack the two sets and shuffle it so it doesn't have any particular order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mix two data clouds into one array (200 points)\n",
    "data=np.vstack((d1,d2))\n",
    "data=np.random.permutation(data)\n",
    "nrow,ncol=data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a random initialization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInitWithData(data, k):\n",
    "    nrow,dim=data.shape\n",
    "    centres=np.zeros((k,dim))\n",
    "    for i in range(k):\n",
    "        centres[i]=data[np.random.randint(nrow)].copy()\n",
    "    return centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and test the function out with k=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centres=randInitWithData(data,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print centres      # Where are the initial centres?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function for going through an iteration of finding membership and update centres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(centres,data):\n",
    "    k,dim=centres.shape\n",
    "    nrow,dim=data.shape\n",
    "    ## Compute distances between centres and data points. \n",
    "    ## Start with the first centre and then stack the rest vertically\n",
    "    distances = np.sum((data-centres[0,:])**2,axis=1)\n",
    "    for j in range(k-1):\n",
    "        distances = np.vstack((distances, np.sum((data-centres[j+1,:])**2,axis=1)))\n",
    "        ## 'distances' is a 2D array: row for centres, column for data items\n",
    "        ## Identify the closest cluster for each data item\n",
    "        cluster = distances.argmin(axis=0)\n",
    "        ## Turn it into a single-column array\n",
    "        cluster = cluster.reshape((nrow,1))\n",
    "        ## Update the cluster centres as the mean of data items that are closest to them\n",
    "        for j in range(k):\n",
    "            thisCluster = np.where(cluster==j,1,0)      # decide membership\n",
    "            if np.sum(thisCluster)>0:\n",
    "                centres[j,:] = np.sum(data*thisCluster,axis=0)/np.sum(thisCluster)\n",
    "    return centres.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcentres=centres.copy()      # keep track of the old centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call iteratre() a number of times and see if it converges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    centres=iterate(centres,data)\n",
    "    print centres\n",
    "    print np.sum(np.abs(centres-oldcentres))    # calculate difference\n",
    "    oldcentres=centres.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code. Do you think it manages to locate the cluster centers in the right places? \n",
    "\n",
    "You may want to write a few functions for the above k-means code to automatically stop iterations once convergence is reached.\n",
    "\n",
    "Let's show them up on the screen again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show them up on the screen. \n",
    "plt.plot(d1[:,0],d1[:,1],'g+')\n",
    "plt.plot(d2[:,0],d2[:,1],'bx')\n",
    "plt.plot(centres[:,0],centres[:,1],'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with another clustering algoithm and take a quick look of clustering evaluation. For this we turn to Scikit.learn, a package specialised for Machine Learning. First, some necessary imports:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use sklearn's data generators to make three blobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we set Eps to 0.3, and the minimum number of neighbours needed for a data point to become core points is 10. The following cluster the dataset using DBSCAN, predict cluster labels for all data points, and mark out core points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "labels = db.labels_\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>fit()</code> function will learn from the data, and label all data points. Note  DBSCAN will mark out core points, border points, and noise points. Noise points are not clustered, so in sklearn's implementation it takes a label of -1 (while others take 0, 1, ...). The number of clusters can be found by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the learning outcome, we can visualize the clustering results. The following code colours the data points according to their cluster IDs, with core points displayed by large markers. Noisy points are displayed in black:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    # plot core points \n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    # non-core points\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can tell the data point types apart: core points, border points, and noise points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the clustering outcome, there are a number of indeces one can use. Here we take a quick look on Silhouette Score.\n",
    "\n",
    "For a data point with a cluster, its Silhouette Coefficient is decided by two scores:\n",
    "- a: The mean distance between a sample and all other points in the same cluster.\n",
    "- b: The mean distance between a sample and all other points in the next nearest cluster.\n",
    "The Silhouette Coefficient $s$ for the data point is then given as:\n",
    "$s = \\displaystyle\\frac{b - a}{max(a, b)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average Silhouette Coefficient of the overall clustering outcome is reported by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.silhouette_score(X, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task C**. Parameters play important part in clustering algorithms. How does the setting of Eps affect the clustering outcome? Print out the number of clusters found, and the Silhouette Score when eps takes value from this list: [0.1,0.15,0.2,0.25,0.3,0.35,0.4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on your findings: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task D**. Use the Sklearn K-means function to redo the clustering with k=2, 3, 4, 5. Compare the outcomes of using two initialization schemes: plain random initialization, and k-means++. Report the Silhouette Scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on your findings:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF LAB 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
